{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Candidates Search Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl \n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "from sklearn.metrics import DistanceMetric\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>video_id</th><th>datetime</th><th>title</th><th>transcript</th></tr><tr><td>str</td><td>datetime[μs]</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;bZr2vhoXSy8&quot;</td><td>2025-02-08 18:10:05</td><td>&quot;I Trained FLUX.1 on My Face (P…</td><td>&quot;flux is a state-of-the-art ima…</td></tr><tr><td>&quot;QvxuR8uLPFs&quot;</td><td>2025-02-03 18:00:00</td><td>&quot;How to Build Customer Segments…</td><td>&quot;although today&#x27;s AI models are…</td></tr><tr><td>&quot;W4s6b2ZM6kI&quot;</td><td>2025-01-31 22:38:22</td><td>&quot;Fine-tuning Multimodal Embeddi…</td><td>&quot;multimodal embedding models br…</td></tr><tr><td>&quot;hOLBrIjRAj4&quot;</td><td>2025-01-22 21:25:16</td><td>&quot;Fine-Tuning Text Embeddings Fo…</td><td>&quot;embedding models represent tex…</td></tr><tr><td>&quot;V1BR2tb_e8g&quot;</td><td>2025-01-13 21:10:47</td><td>&quot;My AI Development Setup (From …</td><td>&quot;hey everyone I&#x27;m Shaw I just g…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌─────────────┬─────────────────────┬───────────────────────────────┬──────────────────────────────┐\n",
       "│ video_id    ┆ datetime            ┆ title                         ┆ transcript                   │\n",
       "│ ---         ┆ ---                 ┆ ---                           ┆ ---                          │\n",
       "│ str         ┆ datetime[μs]        ┆ str                           ┆ str                          │\n",
       "╞═════════════╪═════════════════════╪═══════════════════════════════╪══════════════════════════════╡\n",
       "│ bZr2vhoXSy8 ┆ 2025-02-08 18:10:05 ┆ I Trained FLUX.1 on My Face   ┆ flux is a state-of-the-art   │\n",
       "│             ┆                     ┆ (P…                           ┆ ima…                         │\n",
       "│ QvxuR8uLPFs ┆ 2025-02-03 18:00:00 ┆ How to Build Customer         ┆ although today's AI models   │\n",
       "│             ┆                     ┆ Segments…                     ┆ are…                         │\n",
       "│ W4s6b2ZM6kI ┆ 2025-01-31 22:38:22 ┆ Fine-tuning Multimodal        ┆ multimodal embedding models  │\n",
       "│             ┆                     ┆ Embeddi…                      ┆ br…                          │\n",
       "│ hOLBrIjRAj4 ┆ 2025-01-22 21:25:16 ┆ Fine-Tuning Text Embeddings   ┆ embedding models represent   │\n",
       "│             ┆                     ┆ Fo…                           ┆ tex…                         │\n",
       "│ V1BR2tb_e8g ┆ 2025-01-13 21:10:47 ┆ My AI Development Setup (From ┆ hey everyone I'm Shaw I just │\n",
       "│             ┆                     ┆ …                             ┆ g…                           │\n",
       "└─────────────┴─────────────────────┴───────────────────────────────┴──────────────────────────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pl.read_parquet(\"data/video-transcripts.parquet)\")\n",
    "df_eval = pl.read_csv(\"data/eval-raw.csv\")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embed title and transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "colum_to_embed_list = ['title', 'transcript']\n",
    "model_name_list = ['all-MiniLM-L6-v2', 'multi-qa-distilbert-cos-v1', 'multi-qa-mpnet-base-dot-v1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all-MiniLM-L6-v2_title\n",
      "CPU times: user 358 ms, sys: 162 ms, total: 521 ms\n",
      "Wall time: 2.97 s\n",
      "\n",
      "all-MiniLM-L6-v2_transcript\n",
      "CPU times: user 1.28 s, sys: 186 ms, total: 1.47 s\n",
      "Wall time: 1.3 s\n",
      "\n",
      "multi-qa-distilbert-cos-v1_title\n",
      "CPU times: user 182 ms, sys: 42.6 ms, total: 225 ms\n",
      "Wall time: 426 ms\n",
      "\n",
      "multi-qa-distilbert-cos-v1_transcript\n",
      "CPU times: user 1.35 s, sys: 641 ms, total: 1.99 s\n",
      "Wall time: 4.88 s\n",
      "\n",
      "multi-qa-mpnet-base-dot-v1_title\n",
      "CPU times: user 223 ms, sys: 131 ms, total: 354 ms\n",
      "Wall time: 1.99 s\n",
      "\n",
      "multi-qa-mpnet-base-dot-v1_transcript\n",
      "CPU times: user 3.58 s, sys: 337 ms, total: 3.92 s\n",
      "Wall time: 7.7 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generata embeddings for each combination of column and model\n",
    "\n",
    "# initialize dict to keep track of all text embeddings\n",
    "text_embeddings_dict = {}\n",
    "\n",
    "for model_name in model_name_list:\n",
    "    # define embedding model\n",
    "    model = SentenceTransformer(model_name)\n",
    "    \n",
    "    for colum_name in colum_to_embed_list:\n",
    "        #define text embedding identifier\n",
    "        key_name = model_name + \"_\" + colum_name\n",
    "        print(key_name)\n",
    "        %time embeddings_arr = model.encode(df[colum_name].to_list())\n",
    "        print('')\n",
    "\n",
    "        # append embeddings to dict \n",
    "        text_embeddings_dict[key_name] = embeddings_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embed queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all-MiniLM-L6-v2\n",
      "CPU times: user 151 ms, sys: 88.1 ms, total: 239 ms\n",
      "Wall time: 884 ms\n",
      "\n",
      "multi-qa-distilbert-cos-v1\n",
      "CPU times: user 103 ms, sys: 30.3 ms, total: 133 ms\n",
      "Wall time: 319 ms\n",
      "\n",
      "multi-qa-mpnet-base-dot-v1\n",
      "CPU times: user 559 ms, sys: 156 ms, total: 715 ms\n",
      "Wall time: 1.33 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_embedding_dict = {}\n",
    "\n",
    "for model_name in model_name_list:\n",
    "    # define embedding model\n",
    "    model = SentenceTransformer(model_name)\n",
    "    print(model_name)\n",
    "\n",
    "    # embed query text\n",
    "    %time embeddings_arr = model.encode(df_eval['query'].to_list())\n",
    "    print('')\n",
    "\n",
    "    query_embedding_dict[model_name] = embeddings_arr\n",
    "\n",
    "\n",
    "\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
