{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Candidates Search Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl \n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "from sklearn.metrics import DistanceMetric\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>video_id</th><th>datetime</th><th>title</th><th>transcript</th></tr><tr><td>str</td><td>datetime[μs]</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;bZr2vhoXSy8&quot;</td><td>2025-02-08 18:10:05</td><td>&quot;I Trained FLUX.1 on My Face (P…</td><td>&quot;flux is a state-of-the-art ima…</td></tr><tr><td>&quot;QvxuR8uLPFs&quot;</td><td>2025-02-03 18:00:00</td><td>&quot;How to Build Customer Segments…</td><td>&quot;although today&#x27;s AI models are…</td></tr><tr><td>&quot;W4s6b2ZM6kI&quot;</td><td>2025-01-31 22:38:22</td><td>&quot;Fine-tuning Multimodal Embeddi…</td><td>&quot;multimodal embedding models br…</td></tr><tr><td>&quot;hOLBrIjRAj4&quot;</td><td>2025-01-22 21:25:16</td><td>&quot;Fine-Tuning Text Embeddings Fo…</td><td>&quot;embedding models represent tex…</td></tr><tr><td>&quot;V1BR2tb_e8g&quot;</td><td>2025-01-13 21:10:47</td><td>&quot;My AI Development Setup (From …</td><td>&quot;hey everyone I&#x27;m Shaw I just g…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌─────────────┬─────────────────────┬───────────────────────────────┬──────────────────────────────┐\n",
       "│ video_id    ┆ datetime            ┆ title                         ┆ transcript                   │\n",
       "│ ---         ┆ ---                 ┆ ---                           ┆ ---                          │\n",
       "│ str         ┆ datetime[μs]        ┆ str                           ┆ str                          │\n",
       "╞═════════════╪═════════════════════╪═══════════════════════════════╪══════════════════════════════╡\n",
       "│ bZr2vhoXSy8 ┆ 2025-02-08 18:10:05 ┆ I Trained FLUX.1 on My Face   ┆ flux is a state-of-the-art   │\n",
       "│             ┆                     ┆ (P…                           ┆ ima…                         │\n",
       "│ QvxuR8uLPFs ┆ 2025-02-03 18:00:00 ┆ How to Build Customer         ┆ although today's AI models   │\n",
       "│             ┆                     ┆ Segments…                     ┆ are…                         │\n",
       "│ W4s6b2ZM6kI ┆ 2025-01-31 22:38:22 ┆ Fine-tuning Multimodal        ┆ multimodal embedding models  │\n",
       "│             ┆                     ┆ Embeddi…                      ┆ br…                          │\n",
       "│ hOLBrIjRAj4 ┆ 2025-01-22 21:25:16 ┆ Fine-Tuning Text Embeddings   ┆ embedding models represent   │\n",
       "│             ┆                     ┆ Fo…                           ┆ tex…                         │\n",
       "│ V1BR2tb_e8g ┆ 2025-01-13 21:10:47 ┆ My AI Development Setup (From ┆ hey everyone I'm Shaw I just │\n",
       "│             ┆                     ┆ …                             ┆ g…                           │\n",
       "└─────────────┴─────────────────────┴───────────────────────────────┴──────────────────────────────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pl.read_parquet(\"data/video-transcripts.parquet)\")\n",
    "df_eval = pl.read_csv(\"data/eval-raw.csv\")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embed title and transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "colum_to_embed_list = ['title', 'transcript']\n",
    "model_name_list = ['all-MiniLM-L6-v2', 'multi-qa-distilbert-cos-v1', 'multi-qa-mpnet-base-dot-v1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all-MiniLM-L6-v2_title\n",
      "CPU times: user 60.2 ms, sys: 806 ms, total: 866 ms\n",
      "Wall time: 5.17 s\n",
      "\n",
      "all-MiniLM-L6-v2_transcript\n",
      "CPU times: user 1.26 s, sys: 298 ms, total: 1.56 s\n",
      "Wall time: 1.11 s\n",
      "\n",
      "multi-qa-distilbert-cos-v1_title\n",
      "CPU times: user 56.2 ms, sys: 40.1 ms, total: 96.3 ms\n",
      "Wall time: 207 ms\n",
      "\n",
      "multi-qa-distilbert-cos-v1_transcript\n",
      "CPU times: user 1.23 s, sys: 1.44 s, total: 2.67 s\n",
      "Wall time: 7.94 s\n",
      "\n",
      "multi-qa-mpnet-base-dot-v1_title\n",
      "CPU times: user 64.8 ms, sys: 101 ms, total: 165 ms\n",
      "Wall time: 546 ms\n",
      "\n",
      "multi-qa-mpnet-base-dot-v1_transcript\n",
      "CPU times: user 3.64 s, sys: 711 ms, total: 4.35 s\n",
      "Wall time: 7.44 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generata embeddings for each combination of column and model\n",
    "\n",
    "# initialize dict to keep track of all text embeddings\n",
    "text_embeddings_dict = {}\n",
    "\n",
    "for model_name in model_name_list:\n",
    "    # define embedding model\n",
    "    model = SentenceTransformer(model_name)\n",
    "    \n",
    "    for colum_name in colum_to_embed_list:\n",
    "        #define text embedding identifier\n",
    "        key_name = model_name + \"_\" + colum_name\n",
    "        print(key_name)\n",
    "        %time embeddings_arr = model.encode(df[colum_name].to_list())\n",
    "        print('')\n",
    "\n",
    "        # append embeddings to dict \n",
    "        text_embeddings_dict[key_name] = embeddings_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embed queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all-MiniLM-L6-v2\n",
      "CPU times: user 31.3 ms, sys: 671 ms, total: 702 ms\n",
      "Wall time: 4.54 s\n",
      "\n",
      "multi-qa-distilbert-cos-v1\n",
      "CPU times: user 35.5 ms, sys: 654 ms, total: 690 ms\n",
      "Wall time: 4.96 s\n",
      "\n",
      "multi-qa-mpnet-base-dot-v1\n",
      "CPU times: user 587 ms, sys: 925 ms, total: 1.51 s\n",
      "Wall time: 3.99 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_embedding_dict = {}\n",
    "\n",
    "for model_name in model_name_list:\n",
    "    # define embedding model\n",
    "    model = SentenceTransformer(model_name)\n",
    "    print(model_name)\n",
    "\n",
    "    # embed query text\n",
    "    %time embeddings_arr = model.encode(df_eval['query'].to_list())\n",
    "    print('')\n",
    "\n",
    "    query_embedding_dict[model_name] = embeddings_arr\n",
    "\n",
    "\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate search models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnVideoID_index(df: pl.DataFrame, df_eval: pl.DataFrame, query_n: int):\n",
    "    '''\n",
    "        Function to return the index of the dataframe corresponding to the nth row in evaluation dataframe\n",
    "    '''\n",
    "    return [i for i in range(len(df)) if df['video_id'][i] == df_eval['video_id'][query_n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalTrueRankings(dist_arr_isorted: np.ndarray, df: pl.dataframe.frame.DataFrame, df_eval: pl.dataframe.frame.DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "        Function to return \"true\" video ID rankings for each evaluation query\n",
    "    \"\"\"\n",
    "    \n",
    "    # intialize array to store rankings of \"correct\" search result\n",
    "    true_rank_arr = np.empty((1, dist_arr_isorted.shape[1]))\n",
    "    \n",
    "    # evaluate ranking of correct result for each query\n",
    "    for query_n in range(dist_arr_isorted.shape[1]):\n",
    "    \n",
    "        # return \"true\" video ID's in df\n",
    "        video_id_idx = returnVideoID_index(df, df_eval, query_n)\n",
    "        \n",
    "        # evaluate the ranking of the \"true\" video ID\n",
    "        true_rank = np.argwhere(dist_arr_isorted[:,query_n]==video_id_idx)[0][0]\n",
    "        \n",
    "        # store the \"true\" video ID's ranking in array\n",
    "        true_rank_arr[0,query_n] = true_rank\n",
    "\n",
    "    return true_rank_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize distance metrics to experiment\n",
    "dist_name_list = ['euclidean', 'manhattan', 'chebyshev']\n",
    "sim_name_list = ['cos_sim', 'dot_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# loop through text columns\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column_name \u001b[38;5;129;01min\u001b[39;00m colum_to_embed_list:\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# generate column embedding\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     embedding_arr \u001b[38;5;241m=\u001b[39m \u001b[43mcolum_to_embed_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mcolumn_name\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# loop through distance metrics\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dist_name \u001b[38;5;129;01min\u001b[39;00m dist_name_list:\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m         \u001b[38;5;66;03m# compute distance between video text and query\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
